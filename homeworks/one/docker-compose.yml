version: '4'

services:
  llm-inference-servicel:
    image: "amiralikazi/llm-inference-image:latest"
    container_name: CC_app
    ports:
      - "8080:5000"
    volumes:
      - ./compose_inference_metrics.csv:/app/inside_compose_inference_metrics.csv
    environment:
      - METRICS_LOG_FILE=inside_compose_inference_metrics.csv
